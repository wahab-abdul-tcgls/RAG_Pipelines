{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import bs4\n",
    "import streamlit as st\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "TEXT_MODEL = os.getenv(\"TEXT_MODEL\")\n",
    "SERVICE_NAME = os.getenv(\"AWS_SERVICE_NAME\")\n",
    "REGION_NAME = os.getenv(\"AWS_REGION_NAME\")\n",
    "ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY\")\n",
    "ACCESS_SECRET_KEY = os.getenv(\"AWS_SECRET_KEY\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_ai_text(payload, max_tokens=256, temperature=1, top_p=0.8, top_k=50):\n",
    "#     try:\n",
    "#         prompt = get_prompt(payload)\n",
    "#         model_id = TEXT_MODEL\n",
    "#         body = {\n",
    "#             \"prompt\": prompt,\n",
    "#             \"max_tokens\": max_tokens,\n",
    "#             \"temperature\": temperature,\n",
    "#             \"top_p\": top_p,\n",
    "#             \"top_k\": top_k\n",
    "#         }\n",
    "\n",
    "#         response = client.invoke_model(\n",
    "#             modelId=model_id, \n",
    "#             body=json.dumps(body)\n",
    "#         )\n",
    "\n",
    "#         response_body = json.loads(response[\"body\"].read())\n",
    "#         outputs = response_body.get(\"outputs\")\n",
    "#         generated_text = outputs[0]['text'].replace('\"', '')\n",
    "#         generated_text = generated_text.split('\\n', 1)[0].strip()\n",
    "        \n",
    "#         return generated_text\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         return {\"error\": str(e)}\n",
    "\n",
    "# # Load the LLM from the Bedrock\n",
    "# def load_llm():\n",
    "#     llm = Bedrock(model_id=\"mistral.mistral-large-2402-v1:0\", client=bedrock, model_kwargs={\"max_tokens\": 512})\n",
    "#     return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titan Embeddings using Bedrock client.\n",
    "openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Vector Store for Vector Embeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "\n",
    "# Load RetrievalQA from langchain as it provides a simple interface to interact with the LLM.\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Imports for Data Ingestion\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Import Bedrock for LLM\n",
    "from langchain_community.llms.bedrock import Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the website\n",
    "def data_ingestion():\n",
    "    loader = loader=WebBaseLoader(web_paths=(\"https://www.aluxurytravelblog.com/2024/06/25/luxury-living-with-raffles-in-cambodia/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"entry-content-wrap\")\n",
    "\n",
    "                     )))\n",
    "    documents = loader.load()\n",
    "    # Split the text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                                   chunk_overlap=250)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    # Initialize the Bedrock client with the required API keys and configurations\n",
    "    bedrock = boto3.client(\n",
    "        'bedrock',\n",
    "        service_name=SERVICE_NAME,\n",
    "                       region_name = REGION_NAME,\n",
    "                       aws_access_key_id=ACCESS_KEY_ID,\n",
    "                       aws_secret_access_key=ACCESS_SECRET_KEY)\n",
    "\n",
    "    # Define the model parameters\n",
    "    model_id = TEXT_MODEL\n",
    "    model_kwargs = {\"max_tokens\": 2048,\n",
    "            \"temperature\": 0.8,\n",
    "            \"top_p\": .9,\n",
    "            \"top_k\": 200}\n",
    "\n",
    "    # Load the LLM from Bedrock\n",
    "    llm = bedrock.invoke_endpoint(\n",
    "        EndpointName=model_id,\n",
    "        Body=json.dumps(model_kwargs)\n",
    "    )\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store for Vector Embeddings\n",
    "def setup_vector_store(documents):\n",
    "    # Create a vector store using FAISS from the documents and the embeddings\n",
    "    vector_store = FAISS.from_documents(\n",
    "        documents,\n",
    "        titan_embeddings,\n",
    "    )\n",
    "    # Save the vector store locally\n",
    "    vector_store.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a prompt template\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. Please follow the following rules:\n",
    "1. If the answer is not within the context knowledge, kindly state that you do not know, rather than attempting to fabricate a response.\n",
    "2. If you find the answer, please craft a detailed and concise response to the question at the end. Aim for a summary of max 250 words, ensuring that your explanation is thorough.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "# Now we use langchain PromptTemplate to create the prompt template for our LLM\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RetrievalQA chain and invoke the LLM\n",
    "def get_response(llm, vector_store, query):\n",
    "    retrieval_qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vector_store.as_retriever(\n",
    "            search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "        ),\n",
    "        chain_type_kwargs={\"prompt\": PROMPT},\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "    response = retrieval_qa.invoke(query)\n",
    "    return response['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 18:19:14.437 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "def streamlit_ui():\n",
    "    st.set_page_config(\"Travelblog\")\n",
    "    st.header(\"RAG implementation using AWS Bedrock and Langchain\")\n",
    "\n",
    "    user_question = st.text_input(\"Ask me anything from Travel blog e.g. How good is the destination\")\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.title(\"Update Or Create Vector Embeddings\")\n",
    "\n",
    "        if st.button(\"Update Vector Store\"):\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                docs = data_ingestion()\n",
    "                setup_vector_store(docs)\n",
    "                st.success(\"Done\")\n",
    "\n",
    "    if st.button(\"Generate Response\") or user_question:\n",
    "        # first check if the vector store exists\n",
    "        if not os.path.exists(\"faiss_index\"):\n",
    "            st.error(\"Please create the vector store first from the sidebar.\")\n",
    "            return\n",
    "        if not user_question:\n",
    "            st.error(\"Please enter a question.\")\n",
    "            return\n",
    "        with st.spinner(\"Processing...\"):\n",
    "            faiss_index = FAISS.load_local(\"faiss_index\", embeddings=openai_embeddings,\n",
    "                                           allow_dangerous_deserialization=True)\n",
    "            llm = load_llm()\n",
    "            st.write(get_response(llm, faiss_index, user_question))\n",
    "            st.success(\"Done\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    streamlit_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=WebBaseLoader(web_paths=(\"https://www.aluxurytravelblog.com/2024/05/31/luxury-travel-news-from-around-the-world-may-2024/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"entry-content-wrap\")\n",
    "\n",
    "                     )))\n",
    "\n",
    "text_documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
